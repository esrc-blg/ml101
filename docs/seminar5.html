<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Regularisation | Introduction to Data Science</title>
  <meta name="description" content="Chapter 5 Regularisation | Introduction to Data Science" />
  <meta name="generator" content="bookdown 0.12 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Regularisation | Introduction to Data Science" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Regularisation | Introduction to Data Science" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="seminar4.html">
<link rel="next" href="seminar6.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="lib/bootstrap/3.3.7/js/bootstrap.min.js"></script>
<script src="js/codefolding.js"></script>


<script>
$(document).ready(function () {
  window.initializeCodeFolding();
});
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="lib\bootstrap\3.3.7\css\bootstrap.min.css" type="text/css" />
<link rel="stylesheet" href="css\readthedocs.css" type="text/css" />
<link rel="stylesheet" href="css\custom.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this course</a></li>
<li class="chapter" data-level="1" data-path="seminar1.html"><a href="seminar1.html"><i class="fa fa-check"></i><b>1</b> Linear Regression</a><ul>
<li class="chapter" data-level="1.1" data-path="seminar1.html"><a href="seminar1.html#learning-objectives"><i class="fa fa-check"></i><b>1.1</b> Learning objectives</a><ul>
<li class="chapter" data-level="1.1.1" data-path="seminar1.html"><a href="seminar1.html#dplyr-package"><i class="fa fa-check"></i><b>1.1.1</b> Dplyr package</a></li>
<li class="chapter" data-level="1.1.2" data-path="seminar1.html"><a href="seminar1.html#visualising-a-relationship-bw-two-continuous-variables"><i class="fa fa-check"></i><b>1.1.2</b> Visualising a relationship b/w two continuous variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="seminar2.html"><a href="seminar2.html"><i class="fa fa-check"></i><b>2</b> Classification</a><ul>
<li class="chapter" data-level="2.1" data-path="seminar2.html"><a href="seminar2.html#seminar"><i class="fa fa-check"></i><b>2.1</b> Seminar</a><ul>
<li class="chapter" data-level="2.1.1" data-path="seminar2.html"><a href="seminar2.html#the-non-western-foreigners-data-set"><i class="fa fa-check"></i><b>2.1.1</b> The Non-Western Foreigners Data Set</a></li>
<li class="chapter" data-level="2.1.2" data-path="seminar2.html"><a href="seminar2.html#logistic-regression"><i class="fa fa-check"></i><b>2.1.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="2.1.3" data-path="seminar2.html"><a href="seminar2.html#the-logit-model"><i class="fa fa-check"></i><b>2.1.3</b> The logit model</a></li>
<li class="chapter" data-level="2.1.4" data-path="seminar2.html"><a href="seminar2.html#predict-outcomes-from-logit"><i class="fa fa-check"></i><b>2.1.4</b> Predict Outcomes from logit</a></li>
<li class="chapter" data-level="2.1.5" data-path="seminar2.html"><a href="seminar2.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>2.1.5</b> K-Nearest Neighbors</a></li>
<li class="chapter" data-level="2.1.6" data-path="seminar2.html"><a href="seminar2.html#model-the-underlying-continuous-process"><i class="fa fa-check"></i><b>2.1.6</b> Model the Underlying Continuous Process</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="seminar3.html"><a href="seminar3.html"><i class="fa fa-check"></i><b>3</b> Cross-Validation</a><ul>
<li class="chapter" data-level="3.1" data-path="seminar3.html"><a href="seminar3.html#seminar-1"><i class="fa fa-check"></i><b>3.1</b> Seminar</a><ul>
<li class="chapter" data-level="3.1.1" data-path="seminar3.html"><a href="seminar3.html#the-validation-set-approach"><i class="fa fa-check"></i><b>3.1.1</b> The Validation Set Approach</a></li>
<li class="chapter" data-level="3.1.2" data-path="seminar3.html"><a href="seminar3.html#leave-one-out-cross-validation-loocv"><i class="fa fa-check"></i><b>3.1.2</b> Leave-One-Out Cross-Validation (LOOCV)</a></li>
<li class="chapter" data-level="3.1.3" data-path="seminar3.html"><a href="seminar3.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>3.1.3</b> k-Fold Cross-Validation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="seminar4.html"><a href="seminar4.html"><i class="fa fa-check"></i><b>4</b> Subset Selection</a><ul>
<li class="chapter" data-level="4.1" data-path="seminar4.html"><a href="seminar4.html#seminar-2"><i class="fa fa-check"></i><b>4.1</b> Seminar</a><ul>
<li class="chapter" data-level="4.1.1" data-path="seminar4.html"><a href="seminar4.html#subset-selection-methods"><i class="fa fa-check"></i><b>4.1.1</b> Subset Selection Methods</a></li>
<li class="chapter" data-level="4.1.2" data-path="seminar4.html"><a href="seminar4.html#best-subset-selection"><i class="fa fa-check"></i><b>4.1.2</b> Best Subset Selection</a></li>
<li class="chapter" data-level="4.1.3" data-path="seminar4.html"><a href="seminar4.html#forward-and-backward-stepwise-selection"><i class="fa fa-check"></i><b>4.1.3</b> Forward and Backward Stepwise Selection</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="seminar5.html"><a href="seminar5.html"><i class="fa fa-check"></i><b>5</b> Regularisation</a><ul>
<li class="chapter" data-level="5.1" data-path="seminar5.html"><a href="seminar5.html#seminar-3"><i class="fa fa-check"></i><b>5.1</b> Seminar</a><ul>
<li class="chapter" data-level="5.1.1" data-path="seminar5.html"><a href="seminar5.html#ridge-regression-and-the-lasso"><i class="fa fa-check"></i><b>5.1.1</b> Ridge Regression and the Lasso</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="seminar6.html"><a href="seminar6.html"><i class="fa fa-check"></i><b>6</b> All non-linear (polynomials to splines)</a><ul>
<li class="chapter" data-level="6.1" data-path="seminar6.html"><a href="seminar6.html#seminar-4"><i class="fa fa-check"></i><b>6.1</b> Seminar</a><ul>
<li class="chapter" data-level="6.1.1" data-path="seminar6.html"><a href="seminar6.html#polynomial-regression"><i class="fa fa-check"></i><b>6.1.1</b> Polynomial Regression</a></li>
<li class="chapter" data-level="6.1.2" data-path="seminar6.html"><a href="seminar6.html#step-functions"><i class="fa fa-check"></i><b>6.1.2</b> Step Functions</a></li>
<li class="chapter" data-level="6.1.3" data-path="seminar6.html"><a href="seminar6.html#splines"><i class="fa fa-check"></i><b>6.1.3</b> Splines</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="seminar7.html"><a href="seminar7.html"><i class="fa fa-check"></i><b>7</b> Tree Based Models</a><ul>
<li class="chapter" data-level="7.1" data-path="seminar7.html"><a href="seminar7.html#seminar-5"><i class="fa fa-check"></i><b>7.1</b> Seminar</a><ul>
<li class="chapter" data-level="7.1.1" data-path="seminar7.html"><a href="seminar7.html#classification-trees"><i class="fa fa-check"></i><b>7.1.1</b> Classification Trees</a></li>
<li class="chapter" data-level="7.1.2" data-path="seminar7.html"><a href="seminar7.html#regression-trees"><i class="fa fa-check"></i><b>7.1.2</b> Regression Trees</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="seminar8.html"><a href="seminar8.html"><i class="fa fa-check"></i><b>8</b> Simulation and Monte Carlos</a><ul>
<li class="chapter" data-level="8.1" data-path="seminar8.html"><a href="seminar8.html#seminar-6"><i class="fa fa-check"></i><b>8.1</b> Seminar</a><ul>
<li class="chapter" data-level="8.1.1" data-path="seminar8.html"><a href="seminar8.html#monte-carlo-simulation"><i class="fa fa-check"></i><b>8.1.1</b> Monte Carlo simulation</a></li>
<li class="chapter" data-level="8.1.2" data-path="seminar8.html"><a href="seminar8.html#simulation-approach-to-uncertainty"><i class="fa fa-check"></i><b>8.1.2</b> Simulation approach to uncertainty</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regularisation" class="section level1">
<h1><span class="header-section-number">Chapter 5</span> Regularisation</h1>
<div id="seminar-3" class="section level2">
<h2><span class="header-section-number">5.1</span> Seminar</h2>
<div id="ridge-regression-and-the-lasso" class="section level3">
<h3><span class="header-section-number">5.1.1</span> Ridge Regression and the Lasso</h3>
<p>We start by clearing our workspace, loading the foreigners data, and doing the necessary variable manipulations. The data is available <a href="http://philippbroniecki.github.io/ML2017.io/data/BSAS_manip.RData">here</a>.</p>
<p>We then need to normalize all numeric variables to put them on the same scale. Regularization requires that variables are comparable.</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb146-1" title="1"><span class="co"># clear workspace</span></a>
<a class="sourceLine" id="cb146-2" title="2"><span class="kw">rm</span>(<span class="dt">list=</span><span class="kw">ls</span>())</a>
<a class="sourceLine" id="cb146-3" title="3"></a>
<a class="sourceLine" id="cb146-4" title="4"><span class="co"># load foreigners data</span></a>
<a class="sourceLine" id="cb146-5" title="5"><span class="kw">load</span>(<span class="st">&quot;your directory/BSAS_manip.RData&quot;</span>)</a>
<a class="sourceLine" id="cb146-6" title="6"><span class="kw">head</span>(data2)</a>
<a class="sourceLine" id="cb146-7" title="7"></a>
<a class="sourceLine" id="cb146-8" title="8"><span class="co"># we declare the factor variables</span></a>
<a class="sourceLine" id="cb146-9" title="9">data2<span class="op">$</span>urban &lt;-<span class="st"> </span><span class="kw">factor</span>(data2<span class="op">$</span>urban, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;rural&quot;</span>, <span class="st">&quot;more rural&quot;</span>, <span class="st">&quot;more urban&quot;</span>, <span class="st">&quot;urban&quot;</span>))</a>
<a class="sourceLine" id="cb146-10" title="10">data2<span class="op">$</span>RSex &lt;-<span class="st"> </span><span class="kw">factor</span>(data2<span class="op">$</span>RSex, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;Male&quot;</span>, <span class="st">&quot;Female&quot;</span>))</a>
<a class="sourceLine" id="cb146-11" title="11">data2<span class="op">$</span>health.good &lt;-<span class="st"> </span><span class="kw">factor</span>(data2<span class="op">$</span>health.good, <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;bad&quot;</span>, <span class="st">&quot;fair&quot;</span>, <span class="st">&quot;fairly good&quot;</span>, <span class="st">&quot;good&quot;</span>) )</a>
<a class="sourceLine" id="cb146-12" title="12"></a>
<a class="sourceLine" id="cb146-13" title="13"><span class="co"># categorical variables</span></a>
<a class="sourceLine" id="cb146-14" title="14">cat.vars &lt;-<span class="st"> </span><span class="kw">unlist</span>(<span class="kw">lapply</span>(data2, <span class="cf">function</span>(x) <span class="kw">is.factor</span>(x) <span class="op">|</span><span class="st"> </span><span class="kw">all</span>(x <span class="op">==</span><span class="st"> </span><span class="dv">0</span> <span class="op">|</span><span class="st"> </span>x<span class="op">==</span><span class="dv">1</span>) <span class="op">|</span><span class="st"> </span><span class="kw">all</span>( x<span class="op">==</span><span class="dv">1</span> <span class="op">|</span><span class="st"> </span>x<span class="op">==</span><span class="dv">2</span>) ))</a>
<a class="sourceLine" id="cb146-15" title="15"><span class="co"># normalize numeric variables</span></a>
<a class="sourceLine" id="cb146-16" title="16">data2[, <span class="op">!</span>cat.vars] &lt;-<span class="st"> </span><span class="kw">apply</span>(data2[, <span class="op">!</span>cat.vars], <span class="dv">2</span>, scale)</a></code></pre></div>
<p>In order to run ridge regression, we create a matrix from our dataset using the <code>model.matrix()</code> function. We also need to remove the intercept from the resulting matrix because the function to run ridge regression automatically includes one. Furthermore, we will use the subjective rate of immigrants as response. Consequently, we have to remove <code>over.estimate</code> as it measures the same thing. Lastly, the party affiliation dummies are mutually exclusive, se we have to exclude the model category <code>Cons</code>.</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb147-1" title="1"><span class="co"># covariates in matrix form but remove the intercept, over.estimate, and Cons</span></a>
<a class="sourceLine" id="cb147-2" title="2">x &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(IMMBRIT <span class="op">~</span><span class="st"> </span>. <span class="dv">-1</span> <span class="op">-</span>over.estimate <span class="op">-</span>Cons, data2)</a>
<a class="sourceLine" id="cb147-3" title="3"><span class="co"># check if it looks fine</span></a>
<a class="sourceLine" id="cb147-4" title="4"><span class="kw">head</span>(x)</a></code></pre></div>
<pre><code>  RSexMale RSexFemale       RAge   Househld Lab SNP Ukip BNP GP
1        1          0  0.0144845 -0.2925308   1   0    0   0  0
2        0          1 -1.8065476  0.4540989   0   0    0   0  0
3        0          1  0.5835570 -1.0391604   0   0    0   0  0
4        0          1  1.5509804 -0.2925308   0   0    0   0  0
5        0          1  0.9819078 -1.0391604   0   0    0   0  0
6        1          0 -1.1236606  1.2007285   0   0    0   0  0
  party.other paper WWWhourspW religious employMonths urbanmore rural
1           0     0 -0.5324636         0    -0.203378               0
2           1     0 -0.1566702         0    -0.203378               0
3           1     0 -0.5324636         0     5.158836               0
4           1     1 -0.4071991         1    -0.203378               0
5           1     0 -0.5324636         1    -0.203378               0
6           1     1  1.0959747         0    -0.203378               0
  urbanmore urban urbanurban health.goodfair health.goodfairly good
1               0          1               1                      0
2               0          1               0                      1
3               1          0               0                      0
4               0          0               0                      0
5               1          0               0                      0
6               0          0               0                      1
  health.goodgood      HHInc
1               0  0.7357918
2               0 -1.4195993
3               1 -0.1263647
4               1 -0.3419038
5               1 -0.1263647
6               0 -0.1263647</code></pre>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb149-1" title="1"><span class="co"># response vector</span></a>
<a class="sourceLine" id="cb149-2" title="2">y &lt;-<span class="st"> </span>data2<span class="op">$</span>IMMBRIT</a></code></pre></div>
<div id="ridge-regression" class="section level4">
<h4><span class="header-section-number">5.1.1.1</span> Ridge Regression</h4>
<p>The <code>glmnet</code> package provides functionality to fit ridge regression and lasso models. We load the package and call <code>glmnet()</code> to perform ridge regression. Before being able to run this, we have to install the package like so: <code>install.packages("glmnet")</code>.</p>
<p>The performance of ridge depends on the right choice of lambda. A tuning parameter is a parameter that we need to set and we need to set correctly. We do this by trying different values. All different values are what we refer to as our grid.</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb150-1" title="1"><span class="kw">library</span>(glmnet)</a></code></pre></div>
<pre><code>Loading required package: Matrix</code></pre>
<pre><code>Loading required package: foreach</code></pre>
<pre><code>Loaded glmnet 2.0-18</code></pre>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb154-1" title="1"><span class="co"># tuning parameter</span></a>
<a class="sourceLine" id="cb154-2" title="2">grid &lt;-<span class="st"> </span><span class="dv">10</span><span class="op">^</span><span class="kw">seq</span>(<span class="dv">4</span>, <span class="dv">-2</span>, <span class="dt">length =</span> <span class="dv">100</span>)</a>
<a class="sourceLine" id="cb154-3" title="3"></a>
<a class="sourceLine" id="cb154-4" title="4"><span class="kw">plot</span>(grid, <span class="dt">bty =</span> <span class="st">&quot;n&quot;</span>, <span class="dt">pch =</span> <span class="dv">19</span>,</a>
<a class="sourceLine" id="cb154-5" title="5">     <span class="dt">main =</span> <span class="kw">expression</span>(<span class="kw">paste</span>(<span class="st">&quot;Grid of Tuning Parameters &quot;</span>, lambda)))</a></code></pre></div>
<p><img src="ml101_files/figure-html/unnamed-chunk-97-1.png" width="672" /></p>
<p>We now run ridge regression. We tune <code>lambda</code> and set <code>alpha</code> to 0 which means we carry out ridge regression (instead as for instance the Lasso or the Elastic Net).</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb155-1" title="1"><span class="co"># run ridge; alpha = 0 means do ridge</span></a>
<a class="sourceLine" id="cb155-2" title="2">ridge.mod &lt;-<span class="st"> </span><span class="kw">glmnet</span>(x, y, <span class="dt">alpha =</span> <span class="dv">0</span>, <span class="dt">lambda =</span> grid)</a>
<a class="sourceLine" id="cb155-3" title="3"></a>
<a class="sourceLine" id="cb155-4" title="4"><span class="co"># coefficient shrinkage visualized</span></a>
<a class="sourceLine" id="cb155-5" title="5"><span class="kw">plot</span>(ridge.mod, <span class="dt">xvar =</span> <span class="st">&quot;lambda&quot;</span>, <span class="dt">label =</span> <span class="ot">TRUE</span>)</a></code></pre></div>
<p><img src="ml101_files/figure-html/unnamed-chunk-98-1.png" width="672" /></p>
<p>the object <code>ridge.mod</code> contains a set of coefficients for each of the lambdas which we can access by runing the <code>coef()</code> functio on the object <code>ridge.mod</code>. We tried 100 lambda values and therefore we get 100 coefficient sets. The object is a matrix where rows are variables and columns are the coefficients based on the chosen lambda values.</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb156-1" title="1"><span class="co"># a set of coefficients for each lambda</span></a>
<a class="sourceLine" id="cb156-2" title="2"><span class="kw">dim</span>(<span class="kw">coef</span>(ridge.mod))</a></code></pre></div>
<pre><code>[1]  22 100</code></pre>
<p>We can look at the coefficients at different values for <span class="math inline">\(\lambda\)</span>. Here, we randomly choose two different values and notice that smaller values of <span class="math inline">\(\lambda\)</span> result in larger coefficient estimates and vice-versa.</p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb158-1" title="1"><span class="co"># Lambda and Betas</span></a>
<a class="sourceLine" id="cb158-2" title="2">ridge.mod<span class="op">$</span>lambda[<span class="dv">80</span>]</a></code></pre></div>
<pre><code>[1] 0.1629751</code></pre>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb160-1" title="1"><span class="kw">coef</span>(ridge.mod)[, <span class="dv">80</span>]</a></code></pre></div>
<pre><code>           (Intercept)               RSexMale             RSexFemale 
          -0.061607390           -0.160606935            0.159900421 
                  RAge               Househld                    Lab 
          -0.051728204            0.082363992           -0.138922683 
                   SNP                   Ukip                    BNP 
           0.172199820           -0.206749980            0.425986910 
                    GP            party.other                  paper 
          -0.176955926            0.008250000            0.088331267 
            WWWhourspW              religious           employMonths 
          -0.012922053            0.010790919           -0.001149770 
       urbanmore rural        urbanmore urban             urbanurban 
          -0.009100653            0.049660346            0.119249438 
       health.goodfair health.goodfairly good        health.goodgood 
          -0.051779228           -0.006372962            0.002867504 
                 HHInc 
          -0.291172989 </code></pre>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb162-1" title="1"><span class="kw">sqrt</span>( <span class="kw">sum</span>(<span class="kw">coef</span>(ridge.mod)[<span class="op">-</span><span class="dv">1</span>, <span class="dv">80</span>]<span class="op">^</span><span class="dv">2</span>) )</a></code></pre></div>
<pre><code>[1] 0.6911836</code></pre>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb164-1" title="1">ridge.mod<span class="op">$</span>lambda[<span class="dv">40</span>]</a></code></pre></div>
<pre><code>[1] 43.28761</code></pre>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb166-1" title="1"><span class="kw">coef</span>(ridge.mod)[, <span class="dv">40</span>]</a></code></pre></div>
<pre><code>           (Intercept)               RSexMale             RSexFemale 
         -0.0024035442          -0.0086089993           0.0086089995 
                  RAge               Househld                    Lab 
         -0.0009024882           0.0009302020          -0.0016851561 
                   SNP                   Ukip                    BNP 
          0.0051999098          -0.0051751362           0.0145257558 
                    GP            party.other                  paper 
         -0.0045065860           0.0018619440           0.0002790212 
            WWWhourspW              religious           employMonths 
         -0.0005069474           0.0015920318          -0.0017699007 
       urbanmore rural        urbanmore urban             urbanurban 
         -0.0014946533           0.0006218758           0.0040369054 
       health.goodfair health.goodfairly good        health.goodgood 
          0.0002138639           0.0003043203          -0.0019519248 
                 HHInc 
         -0.0072791705 </code></pre>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb168-1" title="1"><span class="kw">sqrt</span>(<span class="kw">sum</span>(<span class="kw">coef</span>(ridge.mod)[<span class="op">-</span><span class="dv">1</span>, <span class="dv">40</span>]<span class="op">^</span><span class="dv">2</span>))</a></code></pre></div>
<pre><code>[1] 0.02287352</code></pre>
<p>We can get ridge regression coefficients for any value of <span class="math inline">\(\lambda\)</span> using predict.</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb170-1" title="1"><span class="co"># compute coefficients at lambda = s</span></a>
<a class="sourceLine" id="cb170-2" title="2"><span class="kw">predict</span>(ridge.mod, <span class="dt">s =</span> <span class="dv">50</span>, <span class="dt">type =</span> <span class="st">&quot;coefficients&quot;</span>)[<span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(<span class="kw">coef</span>(ridge.mod)), ]</a></code></pre></div>
<pre><code>           (Intercept)               RSexMale             RSexFemale 
         -0.0020916615          -0.0075062040           0.0075062041 
                  RAge               Househld                    Lab 
         -0.0007828438           0.0008050887          -0.0014604733 
                   SNP                   Ukip                    BNP 
          0.0045109868          -0.0045029585           0.0126229971 
                    GP            party.other                  paper 
         -0.0039161618           0.0016221081           0.0002331180 
            WWWhourspW              religious           employMonths 
         -0.0004418724           0.0013894830          -0.0015446673 
       urbanmore rural        urbanmore urban             urbanurban 
         -0.0013036526           0.0005397837           0.0035149833 
       health.goodfair health.goodfairly good        health.goodgood 
          0.0001920935           0.0002676711          -0.0017039940 
                 HHInc 
         -0.0063276702 </code></pre>
<p>We would like to know which value of lambda gives us the model with the best predictive power. We use cross-validation on ridge regression by first splitting the dataset into training and test subsets.</p>
<p>We can choose different values for <span class="math inline">\(\lambda\)</span> by running cross-validation on ridge regression using <code>cv.glmnet()</code>.</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb172-1" title="1"><span class="kw">set.seed</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb172-2" title="2"></a>
<a class="sourceLine" id="cb172-3" title="3"><span class="co"># training data for CV to find optimal lambda, but then test data to estimate test error</span></a>
<a class="sourceLine" id="cb172-4" title="4">cv.out &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(x, y, <span class="dt">alpha =</span> <span class="dv">0</span>, <span class="dt">nfolds =</span> <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb172-5" title="5"></a>
<a class="sourceLine" id="cb172-6" title="6"><span class="co"># illustrate test MSE based on size of lambda</span></a>
<a class="sourceLine" id="cb172-7" title="7"><span class="kw">plot</span>(cv.out)</a></code></pre></div>
<p><img src="ml101_files/figure-html/unnamed-chunk-102-1.png" width="672" /></p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb173-1" title="1"><span class="co"># best performing model&#39;s lambda value</span></a>
<a class="sourceLine" id="cb173-2" title="2">bestlam &lt;-<span class="st"> </span>cv.out<span class="op">$</span>lambda.min</a>
<a class="sourceLine" id="cb173-3" title="3">bestlam</a></code></pre></div>
<pre><code>[1] 0.1726934</code></pre>
<p>The best performing model is the one with <span class="math inline">\(\lambda =\)</span> 0.1726934. We can also extract the mean cross-validated error of the best model.</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb175-1" title="1">cv.out<span class="op">$</span>cvm[ <span class="kw">which</span>(cv.out<span class="op">$</span>lambda <span class="op">==</span><span class="st"> </span>bestlam) ]</a></code></pre></div>
<pre><code>[1] 0.8663222</code></pre>
</div>
<div id="the-lasso" class="section level4">
<h4><span class="header-section-number">5.1.1.2</span> The Lasso</h4>
<p>The lasso model can be estimated in the same way as ridge regression. The <code>alpha = 1</code> parameter tells <code>glmnet()</code> to run lasso regression instead of ridge regression. Lasso is often used more as a variable selection model because a large shrinkage parameter <span class="math inline">\(\lambda\)</span> can cause coefficients of some variables to be exactly zero which means that those variables are excluded from the model.</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb177-1" title="1">lasso.mod &lt;-<span class="st"> </span><span class="kw">glmnet</span>(x, y, <span class="dt">alpha =</span> <span class="dv">1</span>, <span class="dt">lambda =</span> grid)</a>
<a class="sourceLine" id="cb177-2" title="2"><span class="kw">plot</span>(lasso.mod)</a></code></pre></div>
<pre><code>Warning in regularize.values(x, y, ties, missing(ties)): collapsing to
unique &#39;x&#39; values</code></pre>
<p><img src="ml101_files/figure-html/unnamed-chunk-104-1.png" width="672" /></p>
<p>Similarly, we can perform cross-validation using identical step as we did on ridge regression.</p>
<div class="sourceCode" id="cb179"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb179-1" title="1"><span class="co"># cross-validation to pick lambda</span></a>
<a class="sourceLine" id="cb179-2" title="2"><span class="kw">set.seed</span>(<span class="dv">1</span>)</a>
<a class="sourceLine" id="cb179-3" title="3">cv.out &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(x, y, <span class="dt">alpha =</span> <span class="dv">1</span>, <span class="dt">nfolds =</span> <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb179-4" title="4"><span class="kw">plot</span>(cv.out)</a></code></pre></div>
<p><img src="ml101_files/figure-html/unnamed-chunk-105-1.png" width="672" /></p>
<p>We select the best Lambda value and the cross-validation error.</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb180-1" title="1">bestlam &lt;-<span class="st"> </span>cv.out<span class="op">$</span>lambda.min</a>
<a class="sourceLine" id="cb180-2" title="2">cv.out<span class="op">$</span>cvm[ <span class="kw">which</span>(cv.out<span class="op">$</span>lambda <span class="op">==</span><span class="st"> </span>bestlam) ]</a></code></pre></div>
<pre><code>[1] 0.8598552</code></pre>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb182-1" title="1"><span class="co"># compare to ridge regression</span></a>
<a class="sourceLine" id="cb182-2" title="2">out &lt;-<span class="st"> </span><span class="kw">glmnet</span>(x, y, <span class="dt">alpha =</span> <span class="dv">1</span>, <span class="dt">lambda =</span> grid)</a>
<a class="sourceLine" id="cb182-3" title="3">lasso.coef &lt;-<span class="st"> </span><span class="kw">predict</span>(out, <span class="dt">type =</span> <span class="st">&quot;coefficients&quot;</span>, <span class="dt">s =</span> bestlam)[<span class="dv">1</span><span class="op">:</span><span class="dv">16</span>, ]</a>
<a class="sourceLine" id="cb182-4" title="4">lasso.coef[lasso.coef <span class="op">!=</span><span class="st"> </span><span class="dv">0</span>]</a></code></pre></div>
<pre><code>    (Intercept)        RSexMale            RAge        Househld 
    0.123666790    -0.290927784    -0.040834908     0.080195229 
            Lab             SNP            Ukip             BNP 
   -0.109775668     0.001382463    -0.115410323     0.321492204 
             GP           paper urbanmore rural 
   -0.033150926     0.044601323    -0.001227853 </code></pre>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="seminar4.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="seminar6.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": {}
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["ml101.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
